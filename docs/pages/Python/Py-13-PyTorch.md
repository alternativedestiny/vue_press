# 13. PyTorch ç¬”è®°

## 1. å®‰è£…

1. å®‰è£…åŒ…æ¯”è¾ƒå¤§ï¼Œå»ºè®®å…ˆé…ç½®æ¸…åæºï¼Œå‚è€ƒç¬¬ä¸€ç«  [Python ç¯å¢ƒğŸ”—](Python-01-ç¯å¢ƒã€‚md)
2. è¿›å…¥ Pytorch å®˜ç½‘çš„ [å®‰è£…é¡µé¢ğŸ”—](https://pytorch.org/get-started/locally/), æ ¹æ®éœ€è¦é€‰æ‹©ç¯å¢ƒå’Œå®‰è£…ç‰ˆæœ¬

    ![å›¾ 1](../images/2021-06-26_92.png)  

3. æ ¹æ®ç”Ÿæˆçš„å‘½ä»¤å†æœ¬åœ°æ‰§è¡Œå®‰è£…

   > æ¯”å¦‚æ ¹æ®ä¸Šå›¾é€‰æ‹©çš„é€šè¿‡ pip å®‰è£…çš„é€‚ç”¨äº python çš„ cpu ç‰ˆæœ¬ Pytorch

    ```bash
    pip3 install torch torchvision torchaudio
    ```

4. ä½¿ç”¨ gpu è¿›è¡Œè®­ç»ƒéœ€è¦é…ç½® cuda ç¯å¢ƒï¼Œå‚è€ƒ [CUDA å®‰è£…ğŸ”—](Py-01-ç¯å¢ƒ_Env.md##-5.-CUDA-å®‰è£…)

    - Tips1: gpu ç‰ˆæœ¬éœ€è¦å…ˆ NVIDIA æ˜¾å¡å¹¶å®‰è£… CUDAï¼Œæœ€å¥½å…ˆæ ¹æ®åˆ—å‡ºçš„ç‰ˆæœ¬å®‰è£…å¯¹åº”çš„ CUDA ç‰ˆæœ¬ï¼Œæ¯”å¦‚ä¸Šå›¾è¦å®‰è£… CUDA11.1ï¼Œç„¶åå¤åˆ¶å¯¹åº”çš„æŒ‡ä»¤å®‰è£…ç›¸åº”ç‰ˆæœ¬çš„ torch
    - Tips2: å®‰è£…åŒ…æ¯”è¾ƒå¤§ï¼Œå¯ä»¥é€šè¿‡ pip æŒ‡ä»¤åˆ—å‡ºçš„åœ°å€ä¸‹è½½å¥½å®‰è£…åŒ…åï¼Œä»æœ¬åœ°å®‰è£…

    ```python
    import torch

    print(torch.cuda.is_available())    # True è¡¨ç¤ºå¯ç”¨
    # æ˜¾ç¤ºæ˜¾å¡æ•°é‡
    print(torch.cuda.device_count())    # 1 è¡¨ç¤ºåªæœ‰ä¸€å—æ˜¾å¡
    # æ˜¾ç¤ºå½“å‰
    print(torch.cuda.current_device())  # 0 è¡¨ç¤ºå½“å‰åœ¨ç¬¬ä¸€å—æ˜¾å¡ä¸Š
    # æ˜¾ç¤ºæ˜¾å¡å
    print(torch.cuda.get_device_name(0))    # NVIDIA GeForce MX150

    # å®é™…ä½¿ç”¨ GPU è¿›è¡Œè®­ç»ƒçš„æ–¹æ³•
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")  # æœ‰ GPU å°±ç”¨ GPU, å¦åˆ™ç”¨ CPU
    
    model.to(device)  # ç§»åŠ¨æ¨¡å‹åˆ° GPU
    x_data = x_data.to(device) # å°†è®­ç»ƒæ•°æ®æ”¾å…¥ GPU
    y_data = y_data.to(device) # å°†è®­ç»ƒæ•°æ®æ”¾å…¥ GPU
    out = model(x_data)    # è¿›è¡Œè®­ç»ƒ
    ```

## 2. åŸºç¡€ä½¿ç”¨æ–¹æ³•

### 2.1. æ•°æ®å¤„ç†

1. æ•°æ®è½¬æ¢

    ```python
    # torch è½¬ numpy
    torch_data.numpy()

    # numpy è½¬ torch
    torch_data = torch.FloatTensor(np_data).to(device)
    # æˆ–
    torch_data = torch.tensor(np_data, dtype=torch.float32, device=device)
    ```

2. é™ç»´

    ```python
    torch.squeeze(input, dim=None, out=None)
    ```

3. numpy è½¬ tensor

    ```python
    x = torch.from_numpy(x)  # numpy è½¬ tensor
    ```

4. DataLoader ç”¨æ³•

    ```python
    import torch.utils.data as Data

    # x, y åˆ†åˆ«ä¸ºæ•°æ®é›†çš„è¾“å…¥å’Œè¾“å‡º
    x = torch.from_numpy(x.astype(np.float32))  # numpy è½¬ tensor.float32
    y = torch.from_numpy(y.astype(np.float32))  # numpy è½¬ tensor.float32
    
    torch_dataset = Data.TensorDataset(x, y)  # è½¬æ¢æˆ Torch èƒ½è¯†åˆ«çš„ Dataset
    loader = Data.DataLoader(
        dataset=torch_dataset,
        batch_size=batch_size,
        shuffle=True,  # æ˜¯å¦æ‰“ä¹±æ•°æ®
        num_workers=2,  # å¤šçº¿ç¨‹è¯»å–æ•°æ®
    )
    ```

### 2.2. åˆ›å»ºæ¨¡å‹ï¼ˆä»¥å…¨é“¾æ¥ä¸ºä¾‹ï¼‰

1. åˆ›å»ºæ¨¡å‹æ–¹æ³• 1ï¼šç¥ç»ç½‘ç»œå±‚ä¸å…¶ä»–å±‚åˆ†å¼€å†™

    ```python
    class MLP(nn.Module):  # æ¨¡å‹
        def __init__(self):
            super(MLP, self).__init__()  # ç»§æ‰¿ nn.Module.__init__()
            # super().__init__()  # ä¸ä¸Šé¢ä¸€å¥ç­‰æ•ˆ
            self.nn1 = nn.Linear(10, 100)  # ç¬¬ä¸€å±‚çº¿æ€§å±‚ï¼Œè¾“å…¥ 10 ç»´ï¼Œè¾“å‡º 100 ç»´
            self.nn2 = nn.Linear(100, 100)  # ç¬¬äºŒå±‚çº¿æ€§å±‚
            self.nn3 = nn.Linear(100, 10)  # ç¬¬ä¸‰å±‚çº¿æ€§å±‚

        def forward(self, x):
            # ç¬¬ä¸€å±‚
            x = self.nn1(x)  # çº¿æ€§
            x = torch.relu(x)  # æ¿€æ´»å‡½æ•°
            x = F.dropout(x, p=0.1, training=self.training)  # dropout
            # ç¬¬äºŒå±‚
            x = torch.relu(self.nn2(x))  # å¦ä¸€ç§å†™æ³•ï¼šçº¿æ€§+æ¿€æ´»å‡½æ•°
            x = torch.dropout(x, p=0.1, train=self.training)  # dropout
            # ç¬¬ä¸‰å±‚
            x = torch.dropout(torch.tanh(self.nn3(x)), p=0.1, train=self.training)  # çº¿æ€§+æ¿€æ´»+dropout

            return x

    model = MLP()
    print(model)
    """
    MLP(
    (nn1): Linear(in_features=10, out_features=100, bias=True)
    (nn2): Linear(in_features=100, out_features=100, bias=True)
    (nn3): Linear(in_features=100, out_features=10, bias=True)
    )
    """
    ```

2. åˆ›å»ºæ¨¡å‹æ–¹æ³• 2ï¼šç¥ç»ç½‘ç»œå±‚ä¸å…¶ä»–å±‚å†™åˆ°ä¸€èµ·

    ```python
    import torch.nn as nn

    class MLP(nn.Module):  # æ¨¡å‹
        def __init__(self):
            super(MLP, self).__init__()  # ç»§æ‰¿ nn.Module.__init__()
            # super().__init__()  # ä¸ä¸Šé¢ä¸€å¥ç­‰æ•ˆ

            self.model = nn.Sequential(  # åºåˆ—
                nn.Linear(10, 100),  # ç¬¬ä¸€å±‚çº¿æ€§å±‚ï¼Œè¾“å…¥ 10 ç»´ï¼Œè¾“å‡º 100 ç»´
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.1),
                nn.Linear(100, 100),  # ç¬¬äºŒå±‚çº¿æ€§å±‚
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.1),
                nn.Linear(100, 10),  # ç¬¬ä¸‰å±‚çº¿æ€§å±‚
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.1),
            )

        def forward(self, x):
            x = self.model(x)

            return x

    model = MLP()   # åˆ›å»ºæ¨¡å‹
    print(model)    # æ‰“å°æ¨¡å‹ç»“æ„ï¼Œç»“æœå¦‚ä¸‹ï¼š

    """
    MLP(
    (model): Sequential(
        (0): Linear(in_features=10, out_features=100, bias=True)
        (1): ReLU()
        (2): Dropout(p=0.1, inplace=False)
        (3): Linear(in_features=100, out_features=100, bias=True)
        (4): ReLU()
        (5): Dropout(p=0.1, inplace=False)
        (6): Linear(in_features=100, out_features=10, bias=True)
        (7): ReLU()
        (8): Dropout(p=0.1, inplace=False)
    )
    """

    ```

### 2.3. æ¨¡å‹ä¿å­˜ä¸åŠ è½½

1. ä¿å­˜æ¨¡å‹

    ```python
    # åªä¿å­˜æ¨¡å‹å‚æ•°ï¼Œä½“ç§¯å°ï¼Œé€Ÿåº¦å¿«
    torch.save(net.state_dict(), 'model_para')

    # ä¿å­˜å®Œæ•´çš„æ¨¡å‹
    torch.save(net, 'model_name')
    ```

2. åŠ è½½æ¨¡å‹

    > map_location ä¸è®¾ç½®çš„è¯ï¼Œæ¨¡å‹ä¼šåŠ è½½åˆ°ä¿å­˜æ¨¡å‹çš„è®¾å¤‡

    ```python
    # åŠ è½½æ¨¡å‹å‚æ•°
    model = xxxNet()  # å…ˆåˆ›å»ºæ¨¡å‹
    static_dict = torch.load('model_para', map_location='cuda:0')  # åŠ è½½æ¨¡å‹å‚æ•°æ–‡ä»¶
    model.load_state_dict(static_dict)  # å°†æ¨¡å‹å‚æ•°åŠ è½½åˆ°æ¨¡å‹ä¸­

    # åŠ è½½æ•´ä¸ªæ¨¡å‹
    model = torch.load('model_name')
    model = torch.load('model_name', map_location=torch.device('cpu'))   # åŠ è½½æ¨¡å‹åˆ° cpu
    ```

## 3. Torch æ¨¡å‹

1. [å®˜æ–¹æ–‡æ¡£ğŸ”—](https://pytorch.org/docs/stable/nn.html)

### 3.1. å·ç§¯å±‚ Convolution Layers

1. å·ç§¯å±‚ï¼šconv2d äºŒç»´å·ç§¯ï¼Œ[å·ç§¯åŠ¨ç”»ğŸ”—](https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md)

    ```python
    import torch nn as nn
    import torch.nn.functional as F

    nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)
    # in_channels: è¾“å…¥ç»´åº¦
    # out_channels: è¾“å‡ºç»´åº¦
    # kernel_size: å†…æ ¸ç»´åº¦
    # stride: åç§»é‡
    # padding: å¡«å……ï¼ˆçŸ©é˜µè¾¹ç¼˜å¡«å……çš„ç»´åº¦ï¼‰

    F.conv2d(input, weight, bias=None, stride=1, padding=0)
    # input: è¾“å…¥
    # weight: å·ç§¯æ ¸
    # bias: åç½®ï¼ˆç›¸å½“äºåŠ ä¸€ä¸ªå¸¸é‡ï¼‰
    # stride: åç§»é‡
    # padding: å¡«å……ï¼ˆçŸ©é˜µè¾¹ç¼˜å¡«å……çš„ç»´åº¦ï¼‰

    ```

### 3.2. æ± åŒ–å±‚ Pooling Layers

1. æ± åŒ–å±‚ï¼šmaxpool2d äºŒç»´æœ€å¤§æ± åŒ–ï¼Œå‡å°æ•°æ®ç»´æ•°ï¼ŒåŠ å¿«è®­ç»ƒé€Ÿåº¦

    ```python
    nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)
    # kernel_size: æ± åŒ–ç»´åº¦
    # stride: åç§»é‡ï¼Œé»˜è®¤å€¼=kernel_size
    # padding: å¡«å……
    # dilation: ç©ºæ´å·ç§¯
    # ceil_mode: True=ceil æ¨¡å¼ï¼Œfalse=floor æ¨¡å¼
    ```

### 3.3. çº¿æ€§å±‚ Liner Layers

1. çº¿æ€§å±‚ï¼ˆå…¨é“¾æ¥ï¼‰

    ```python
    # in_features: è¾“å…¥ç»´æ•°
    # out_features: è¾“å‡ºç»´æ•°
    # bias: æ˜¯å¦å­¦ä¹ åç½®é‡
    nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)
    ```

### 3.4. æ¿€æ´»å‡½æ•° Non-liner Activations

1. éçº¿æ€§æ¿€æ´»

    ```python
    nn.ReLU(inplace=False)   # 0 if x < 0 else x
    nn.Sigmoid()
    nn.Tanh()
    ```

    ![å›¾ 2](../images/2022-11-23_12.png)  

### 3.5. æ—©åœæ³• EarlyStopping

1. æ—©åœç±»å®šä¹‰

    ```python
    class EarlyStopping:
        """
        Early stopping to stop the training when the loss does not improve after
        certain epochs.
        """

        def __init__(self, patience=5, min_delta=0):
            """
            :param patience: how many epochs to wait before stopping when loss is
                not improving
            :param min_delta: minimum difference between new loss and old loss for
                new loss to be considered as an improvement
            """
            self.patience = patience
            self.min_delta = min_delta
            self.counter = 0
            self.best_loss = None
            self.early_stop = False

        def __call__(self, val_loss):
            if self.best_loss is None:
                self.best_loss = val_loss
            elif self.best_loss - val_loss > self.min_delta:
                self.best_loss = val_loss
                # reset counter if validation loss improves
                self.counter = 0
            elif self.best_loss - val_loss < self.min_delta:
                self.counter += 1
                print(f"INFO: Early stopping counter {self.counter} of {self.patience}")
                if self.counter >= self.patience:
                    print('INFO: Early stopping')
                    self.early_stop = True
    ```

2. ä½¿ç”¨

    ```python
    # é¦–å…ˆåœ¨å¤–éƒ¨å®šä¹‰æ—©åœç±»
    early_stopping = EarlyStopping()

    # åœ¨ epoch è®­ç»ƒçš„å¾ªç¯å†…æ ¹æ® loss è¿›è¡Œæ—©åœï¼Œä¹Ÿå¯ä»¥å°† loss æ¢æˆå…¶ä»–è§‚æµ‹å€¼
    early_stopping(train_loss)
    if early_stopping.early_stop:
        break
    ```

## 4. å®ä¾‹

### 4.1. å…¨é“¾æ¥ç¥ç»ç½‘ç»œ

1. åŸºç¡€ MLP

    ```python
    import torch
    import torch.nn as nn
    # import torch.nn.functional as F
    import torch.utils.data as Data
    import pandas as pd
    import numpy as np
    from sklearn import preprocessing

    class MLP(nn.Module):  # åˆ›å»º MLP æ¨¡å‹

        def __init__(self):
            super(MLP, self).__init__()  # ç»§æ‰¿ nn.Module.__init__()

            self.model = nn.Sequential(  # åºåˆ—
                nn.Linear(60, 1000),  # ç¬¬ä¸€å±‚çº¿æ€§å±‚ï¼Œè¾“å…¥ 60 ç»´ï¼Œè¾“å‡º 100 ç»´
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.2),
                nn.Linear(1000, 2000),  # ç¬¬äºŒå±‚çº¿æ€§å±‚
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.2),
                nn.Linear(2000, 1000),  # ç¬¬ä¸‰å±‚çº¿æ€§å±‚
                nn.ReLU(),  # æ¿€æ´»å‡½æ•°
                nn.Dropout(0.1),
                nn.Linear(1000, 500),  # ç¬¬å››å±‚çº¿æ€§å±‚
                nn.Tanh(),  # æ¿€æ´»å‡½æ•°
                nn.Linear(500, 60)  # ç¬¬äº”å±‚è¾“å‡ºå±‚
            )

        def forward(self, x):
            output = self.model(x)

            return output

    def train():
        m_model = MLP()
        m_model.to(device)  # ç§»åŠ¨æ¨¡å‹åˆ° GPU
        print(m_model)
        lossfunc = nn.MSELoss()  # æŸå¤±å‡½æ•°
        optimizer = torch.optim.Adam(m_model.parameters(), learning_rate)  # ä¼˜åŒ–å™¨

        x, y, y_o = get_data()
        x = torch.from_numpy(x.astype(np.float32))  # numpy è½¬ tensor
        y = torch.from_numpy(y.astype(np.float32))  # numpy è½¬ tensor
        torch_dataset = Data.TensorDataset(x, y)  # è½¬æ¢æˆ Torch èƒ½è¯†åˆ«çš„ Dataset
        loader = Data.DataLoader(
            dataset=torch_dataset,
            batch_size=batch_size,
            shuffle=True,  # æ˜¯å¦æ‰“ä¹±æ•°æ®
            num_workers=2,  # å¤šçº¿ç¨‹è¯»å–æ•°æ®
        )

        for epoch in range(epochs):
            train_loss = 0
            for i, (batch_x, batch_y) in enumerate(loader):
                train_x = batch_x.cuda()
                train_y = batch_y.cuda()
                # print(batch_x.size())
                optimizer.zero_grad()  # æ¸…ç©ºä¸Šä¸€æ­¥çš„æ®‹ä½™æ›´æ–°å‚æ•°å€¼
                out = m_model(train_x)
                loss = lossfunc(out, train_y)  # è®¡ç®—è¯¯å·®
                loss.backward()  # è¯¯å·®åå‘ä¼ æ’­ï¼Œè®¡ç®—å‚æ•°æ›´æ–°å€¼
                optimizer.step()  # å°†å‚æ•°æ›´æ–°å€¼æ–½åŠ åˆ° net çš„ parameters ä¸Š
                train_loss += loss.data

            train_loss = train_loss / len(loader)
            print(f"Epoch {epoch + 1} : Train_loss = {train_loss:.6f}")
    ```

## 5. å›¾ç¥ç»ç½‘ç»œ GNN

### 5.1. å›¾ç¥ç»ç½‘ç»œåŸºç¡€

1. å›¾ç¥ç»ç½‘ç»œæ¦‚è¿°

    > å›¾å·ç§¯ç½‘ç»œ (Graph Convolutional Networks) ä½œä¸ºæœ€è¿‘å‡ å¹´å…´èµ·çš„ä¸€ç§åŸºäºå›¾ç»“æ„çš„å¹¿ä¹‰ç¥ç»ç½‘ç»œï¼Œå› ä¸ºå…¶ç‹¬ç‰¹çš„è®¡ç®—èƒ½åŠ›ï¼Œå—åˆ°äº†å­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å…³æ³¨ä¸ç ”ç©¶ã€‚ä¼ ç»Ÿæ·±åº¦å­¦ä¹ æ¨¡å‹å¦‚ LSTM å’Œ CNN åœ¨æ¬§å¼ç©ºé—´ä¸­è¡¨ç°ä¸ä¿—ï¼Œå´æ— æ³•ç›´æ¥åº”ç”¨åœ¨éæ¬§å¼æ•°æ®ä¸Šã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…ä»¬é€šè¿‡å¼•å…¥å›¾è®ºä¸­æŠ½è±¡æ„ä¹‰ä¸Šçš„â€œå›¾â€æ¥è¡¨ç¤ºéæ¬§å¼ç©ºé—´ä¸­çš„ç»“æ„åŒ–æ•°æ®ï¼Œå¹¶é€šè¿‡å›¾å·ç§¯ç½‘ç»œæ¥æå–ï¼ˆgraphï¼‰çš„æ‹“æ‰‘ç»“æ„ï¼Œä»¥æŒ–æ˜è•´è—åœ¨å›¾ç»“æ„æ•°æ®ä¸­çš„æ·±å±‚æ¬¡ä¿¡æ¯ã€‚

2. å›¾ç¥ç»ç½‘ç»œï¼ˆGraph Neural Networkï¼‰æ˜¯ä¸€ç§ä¸“é—¨å¤„ç†å›¾ç»“æ„æ•°æ®çš„ç¥ç»ç½‘ç»œï¼Œç›®å‰è¢«å¹¿æ³›åº”ç”¨äºæ¨èç³»ç»Ÿã€é‡‘èé£æ§ã€ç”Ÿç‰©è®¡ç®—ä¸­ã€‚å›¾ç¥ç»ç½‘ç»œçš„ç»å…¸é—®é¢˜ä¸»è¦æœ‰ä¸‰ç§ï¼ŒåŒ…æ‹¬èŠ‚ç‚¹åˆ†ç±»ã€è¿æ¥é¢„æµ‹å’Œå›¾åˆ†ç±»ä¸‰ç§ã€‚[ğŸ”—](https://aistudio.baidu.com/aistudio/projectdetail/1462003?channelType=0&channel=0)

3. å¸¸è§å›¾ç¥ç»ç½‘ç»œ

    | ç½‘ç»œ | åç§°         | å¤‡æ³¨                     |
    | ---- | ------------ | ------------------------ |
    | GCN  | å›¾å·ç§¯ç½‘ç»œ   | é€‚ç”¨äºæ— å‘å›¾ï¼Œä¸å¸¦è¾¹ä¿¡æ¯ |
    | GAT  | å›¾æ³¨æ„åŠ›ç½‘ç»œ |

### 5.2. å›¾ç§ç±»

1. æ— å‘å›¾
2. å¼‚æ„å›¾
3. å¸¦è¾¹ä¿¡æ¯çš„å›¾
4. åŠ¨æ€å›¾
5. å¤šç»´å›¾

### 5.3. PyTorch æ„å»º GNN

1. GCN

    ```python
    import torch 
    from torch import nn 
    
    class GCN(nn.Module):
        def __init__(self, *sizes):
            super().__init__() 
            self.layers = nn.ModuleList([ nn.Linear(x, y) for x, y in zip(sizes[:-1], sizes[1:]) ]) 
        def forward(self, vertices, edges): 
            # ----- æ„å»ºé‚»æ¥çŸ©é˜µ ----- 
            # ä»è‡ªæˆ‘è¿æ¥å¼€å§‹ 
            adj = torch.eye(len(vertices)) 
            # è¾¹åŒ…å«è¿æ¥çš„å®šç‚¹ï¼š[vertex_0, vertex_1] 
            adj[edges[:, 0], edges[:, 1]] = 1 
            adj[edges[:, 1], edges[:, 0]] = 1 
            # ----- å‰å‘æ•°æ®ä¼ é€’ ----- 
            for layer in self.layers: 
                vertices = torch.sigmoid(layer(adj @ vertices)) 
                return vertices
    ```

### 5.4. å›¾ç¥ç»ç½‘ç»œåº“ torch_geometric å®‰è£…

1. æ‰“å¼€ [torch_geometric å®˜ç½‘ğŸ”—](https://pytorch-geometric.readthedocs.io/en/latest/)
2. ç®€æ˜“æ–¹æ³• [æ¨è]ï¼Œæ ¹æ® `Quick Start` é€‰æ‹©ç›¸åº”çš„ç‰ˆæœ¬å’Œç³»ç»Ÿï¼Œå¤åˆ¶ä¸‹é¢çš„ pip æŒ‡ä»¤å®‰è£…å³å¯ï¼Œå¦‚æœæ²¡æœ‰åˆ—å‡ºåˆé€‚çš„ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥è‡ªè¡Œä¿®æ”¹ pip æŒ‡ä»¤ä¸­çš„ç‰ˆæœ¬å·è¿›è¡Œå®‰è£…
   ![å›¾ 3](../images/2022-12-09_72.png)  

3. å¦‚æœåœ¨ `Quick Start` æ²¡æœ‰æ‰¾åˆ°å¯¹åº”ç‰ˆæœ¬å¯ä»¥ç”¨å¦‚ä¸‹æ–¹æ³•
    1. æ‰¾åˆ° Installation ç•Œé¢ï¼Œç‚¹å‡»å›¾ç‰‡ä¸­çš„`here`
    ![å›¾ 1](../images/2022-12-09_17.png)  
    2. æ ¹æ®è‡ªå·±çš„ torch ç‰ˆæœ¬å’Œç³»ç»Ÿé€‰æ‹©ç›¸åº”çš„æ–‡ä»¶å¤¹ï¼Œæ¯”å¦‚è¦å®‰è£… CPU ç‰ˆæœ¬ï¼Œtorch=1.13.0, å°±ç‚¹å‡»ç›¸åº”çš„ `torch-1.13.0+cpu` ç‰ˆæœ¬
    ![å›¾ 2](../images/2022-12-09_61.png)  
    3. æ ¹æ® python ç‰ˆæœ¬ä¸‹è½½ç›¸åº”çš„ whl æ–‡ä»¶ï¼Œæ¯”å¦‚`Windows å¹³å°ï¼Œpython=3.9`è¦æ‰¾åˆ° `cp39-win_amd64.whl` åç¼€çš„æ–‡ä»¶ï¼Œéœ€è¦å®‰è£…çš„æ–‡ä»¶æœ‰ 4 ä¸ªï¼š`torch_cluster`, `torch_scatter`, `torch_sparse`, `torch_spline_conv`, ä¸è¿‡ç¼ºå°‘`torch-geometric`åŒ…ï¼Œè¿˜æ˜¯éœ€è¦é€šè¿‡ä¸€æ–¹æ³•çš„ pip å®‰è£…
    4. ä¸‹è½½å®Œæˆåï¼Œåœ¨è¦å®‰è£…çš„ python ç¯å¢ƒä¸­ç”¨ pip æŒ‡ä»¤å®‰è£…

### 5.5. torch_geometric ä½¿ç”¨

1. æ•°æ®ç¤ºä¾‹

    ```python
    from torch_geometric.datasets import KarateClub # å¼•å…¥æ•°æ®é›† 

    dataset = KarateClub()
    data = dataset[0]

    # x = [æ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾ç»´åº¦], edge_index=[æ ·æœ¬å…³ç³»ï¼Œå…³ç³»ä¸ªæ•°], y=[æ ‡ç­¾], train_mask=[æœ‰æ— æ ‡ç­¾]
    # å³ [ç‚¹æ•°ï¼Œç‚¹çš„ç‰¹å¾], [è¾¹ï¼Œè¾¹æ•°]
    print(data) # Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])
    ```

2. è®ºæ–‡åˆ†ç±»å®ä¾‹ï¼ˆå¯ç›´æ¥è¿è¡Œï¼Œéœ€è¦ä¸‹è½½æ•°æ®é›†ï¼Œæ•°æ®é›†æ— æ³•ä¸‹è½½æ—¶å¯æ‰‹åŠ¨ä¸‹è½½ç„¶åæ”¾å…¥å¯¹åº”ç›®å½•ï¼‰

    ```python
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch_geometric.nn as gnn
    from torch_geometric.datasets import Planetoid
    from torch_geometric.transforms import NormalizeFeatures

    class GCN(nn.Module):  # æ¨¡å‹
        def __init__(self, hidden):
            super().__init__()
            # ç¬¬ä¸€å±‚ GCNConv(1433, 16)ï¼šæ¯ä¸ªç‚¹çš„ç‰¹å¾ç»´åº¦ï¼Œéšè—å±‚
            self.conv1 = gnn.GCNConv(dataset.num_features, hidden)
            # ç¬¬äºŒå±‚ GCNConv(16, 7)ï¼šéšè—å±‚ï¼Œè¾“å‡ºç»´åº¦ï¼ˆåˆ†ç±»æ•°ï¼‰
            self.conv2 = gnn.GCNConv(hidden, dataset.num_classes)

        def forward(self, x, edge_index):
            x = self.conv1(x, edge_index)
            x = x.relu()
            x = F.dropout(x, p=0.5, training=self.training)
            x = self.conv2(x, edge_index)

            return x

    def train():  # è®­ç»ƒ
        model.train()
        optimizer.zero_grad()
        out = model(data.x, data.edge_index)
        loss = criterion(out[data.train_mask], data.y[data.train_mask])
        loss.backward()
        optimizer.step()

        return loss

    def test():  # æµ‹è¯•
        model.eval()
        out = model(data.x, data.edge_index)
        pred = out.argmax(dim=1)
        test_correct = pred[data.test_mask] == data.y[data.test_mask]
        test_acc = int(test_correct.sum()) / int(data.test_mask.sum())
        return test_acc

    if __name__ == '__main__':
        # æ•°æ®é›†ï¼š2708 ä¸ªèŠ‚ç‚¹ï¼Œæ¯ä¸ªèŠ‚ç‚¹ 1433 ä¸ªç‰¹å¾ï¼Œ10556 æ¡è¾¹
        dataset = Planetoid(root='../data/Planetoid', name='Cora', transform=NormalizeFeatures())
        # Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
        data = dataset.data
        print(f"data_x shape = {data.x.shape}")  # torch.Size([2708, 1433])
        print(f"edge_index shape = {data.edge_index.shape}")  # torch.Size([2, 10556])

        model = GCN(hidden=16)
        print(model)

        optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
        criterion = torch.nn.CrossEntropyLoss()

        for epoch in range(100):
            los = train()
            print(f"Epoch {epoch}, Loss={los:.4f}")

        test_out = test()
        print(f"Test out accuracy: {test_out:.4f}")
    ```

### 5.6. torch_geometric æ•°æ®é›†

1. æ•°æ®é›†ç»“æ„
    - data.x: èŠ‚ç‚¹å±æ€§çŸ©é˜µï¼Œç‰¹å¾ [èŠ‚ç‚¹æ•°ï¼ŒèŠ‚ç‚¹ç‰¹å¾ç»´åº¦]
    - data.edge_indexï¼šè¾¹ä¿¡æ¯ [2, è¾¹æ•°é‡]

2. åˆ›å»ºæ•°æ®é›†

    ```python
    from torch_geometric.data import Data

    # åˆ›å»ºæ•°æ®é›†
    data = Data(x=torch.from_numpy(feat.astype(np.float32)), edge_index=torch.tensor(edges, dtype=torch.long))
    # ç»™æ•°æ®é›†å¢åŠ æ–°çš„é™„åŠ æ•°æ®ï¼Œè¿™é‡Œå¢åŠ äº†è®­ç»ƒé›†çš„åºå·å’Œæ ‡ç­¾ï¼Œä¹Ÿå¯è‡ªè¡Œæ·»åŠ å…¶ä»–æ•°æ®ï¼Œåå­—éšæ„
    data.train_index = train[:, 0]
    data.train_label = train[:, 1]
    ```

## 6. å¼ºåŒ–å­¦ä¹  ReinforcementLearning

### 6.1. DQNï¼ˆDeep Q Networkï¼‰
