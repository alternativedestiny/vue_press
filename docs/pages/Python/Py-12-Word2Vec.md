# 12. Word2Vec

## 1. ç®€ä»‹

## 2. åº”ç”¨

### 2.1. å®‰è£…

1. å®‰è£…`gensim`

    ```bash
    pip install gensim
    ```

2. ä¸­æ–‡è®­ç»ƒéœ€è¦ç”¨çš„åˆ†è¯ï¼Œå¯ä»¥ç”¨`jieba`

    ```bash
    pip install jieba
    ```

### 2.2. è®­ç»ƒ

1. ä¸»è¦æ¨¡å‹å‚æ•°

    | å‚æ•°        | é»˜è®¤å€¼ | åŠŸèƒ½                        |
    | ----------- | ------ | --------------------------- |
    | sentences   |        | è¯­æ–™ï¼ˆå¿…è¦å‚æ•°ï¼‰              |
    | vector_size | 100    | è¯å‘é‡ç»´åº¦                  |
    | window      | 5      | è¯å‘é‡ä¸Šä¸‹æ–‡çš„æœ€å¤§è·ç¦»      |
    | sg          | 0      | é€‰æ‹©æ¨¡å‹ï¼š0-CBOW,1-ShipGram |

2. è®­ç»ƒç¤ºä¾‹ï¼Œ<a href="../files/in_the_name_of_people_segment.txt" target="_blank">wenjian</a>

    ```python
    import logging
    import os
    from gensim.models import word2vec

    # æ˜¾ç¤ºè®­ç»ƒä¿¡æ¯
    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)
    # è¯»å–è®­ç»ƒè¯­æ–™ï¼ˆä¸­æ–‡åˆ†è¯ç»“æœï¼‰
    sentences = word2vec.LineSentence('./in_the_name_of_people_segment.txt')
    # è®­ç»ƒ
    model = word2vec.Word2Vec(sentences, vector_size=100, window=3, min_count=5)
    # ä¿å­˜æ¨¡å‹
    model.save('w2v.model')
    ```

### 2.3. ä½¿ç”¨æ¨¡å‹

1. æ‰¾å‡ºæŸä¸ªè¯å‘é‡æœ€ç›¸è¿‘çš„è¯é›†åˆ

    ```python
    # åŠ è½½æ¨¡å‹
    model2 = word2vec.Word2Vec.load('w2v.model')

    # ç›¸è¿‘è¯ä¸ªæ•°
    req_count = 5
    for key in model2.wv.similar_by_word('æè¾¾åº·', topn=100):
        if len(key[0]) == 3:
            req_count -= 1
            print(key[0], key[1])
            if req_count == 0:
                break
    ```

2. çœ‹ä¸¤ä¸ªè¯çš„ç›¸è¿‘ç¨‹åº¦

    ```python
    # åŠ è½½æ¨¡å‹
    model2 = word2vec.Word2Vec.load('w2v.model')
    print(model2.wv.similarity('æè¾¾åº·', 'å´æ…§èŠ¬'))
    ```

3. æ‰¾å‡ºä¸åŒç±»çš„è¯

    ```python
    # åŠ è½½æ¨¡å‹
    model2 = word2vec.Word2Vec.load('w2v.model')
    print(model2.wv.doesnt_match("æ²™ç‘é‡‘ é«˜è‚²è‰¯ æè¾¾åº· åˆ˜åº†ç¥".split()))
    ```

## 3. å‚è€ƒ

- åˆ˜å»ºå¹³ [ç”¨ gensim å­¦ä¹  word2vecğŸ”—](https://www.cnblogs.com/pinard/p/7278324.html)
