# 层次聚类

## 1. 相关性分析

1. 相关性系数：其范围（-1，1），正值表示正相关，负值表示负相关，0表示不相关
2. Pearson 皮尔逊

    > 两个变量中的任意一个不能一成不变，即标准差为0

    ```python
    from scipy.stats import pearsonr
    # pear：pearson相关系数
    # p：p值越小，表示相关系数越显著，一般p值在500个样本以上时有较高的可靠性
    pear, p = pearsonr(x, y)  
    ```

3. Spearman 斯皮尔曼

    > 没有数据条件要求，使用较广

    ```python
    from scipy.stats import spearmanr
    rho, p = spearmanr(x, y)
    ```

4. Kendall 肯德尔

    > 计算对象是分类变量

    ```python
    from scipy.stats import kendalltau
    tau, p = kendalltau(x, y)
    ```

## 2. 分层（层次）聚类

1. 以相关性系数作为聚类依据，其数据格式如下

    | Pear | a    | b    | c    | d    |
    | ---- | ---- | ---- | ---- | ---- |
    | a    | 1    | 0.53 | 0.67 | 0.98 |
    | b    | 0.53 | 1    | 0.89 | 0.21 |
    | c    | 0.67 | 0.89 | 1    | 0.74 |
    | d    | 0.98 | 0.21 | 0.74 | 1    |

2. 聚类方法

    ```python
    import pandas as pd
    from sklearn.cluster import AgglomerativeClustering

    data = pd.DataFrame({'a': [1.0, 0.53, 0.67, 0.98],
                        'b': [0.53, 1.0, 0.89, 0.21],
                        'c': [0.67, 0.89, 1.0, 0.74],
                        'd': [0.98, 0.21, 0.74, 1.0]},
                        index=list('abcd'))

    # linkage：ward-单链接（最小距离），complete-全链接（最大距离），average-均链接（平均距离）
    sk = AgglomerativeClustering(2, linkage='ward')  # 分2个区
    sk.fit(data)
    index = data.index  # [a,b,c,d]
    # 分区结果
    out = sk.labels_  # [1 0 0 1]
    ```

    > 对应的结果：两个区域分别为[a, d]和[b, c]

## 3. 参考

- [Agglomerative层次聚类](https://blog.csdn.net/Haiyang_Duan/article/details/77995665)
